{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime as dt\n",
    "from datetime import datetime, date\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\Romina\\\\Desktop\\\\thesis')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df= pd.read_csv(\"log_data_final.csv\", low_memory=False)\n",
    "\n",
    "df= pd.read_csv(\"final_session_30mins.csv\", low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head(30)\n",
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.info()\n",
    "#df['_source.doc.@fields.event'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identify sessions with queries- that is sessions with a query term search which include the sessions with atleast one event\n",
    "grouped = df.groupby('session_no')['ip','q'].count().reset_index()\n",
    "grouped.head()\n",
    "#non_abandon=grouped[(grouped['_source.user.ip'] > 1) & (grouped['_source.doc.@fields.filters.q'] > 0)]\n",
    "#SESSIONS With atleast a search Query- this includes both abandoned and non-abandoned queries\n",
    "sessionsWithQ=grouped[(grouped['q'] > 0)]\n",
    "sessionsWithQ.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the sessions with one event that have a query and they are abandons in our case (same as sessions without click)\n",
    "# test=non_abandon[non_abandon['_source.user.ip'] == 1]\n",
    "# test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sessionsWithQ_dat=df[df['session_no'].isin(sessionsWithQ['session_no'])].reset_index()\n",
    "sessionsWithQ_dat=sessionsWithQ_dat.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis=1)\n",
    "sessionsWithQ_dat.head()\n",
    "#non_abandon_dat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get the result id for all the shown results\n",
    "sessions=sessionsWithQ_dat[['session_no', 'ip','event','http_referer','url',\n",
    "                          'result_id','q']]\n",
    "sessions.head(100)\n",
    "#sessions.to_csv(\"sessions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flag sessions with views (click) and those accessed portal (Go To Data Provider, Go To Service Provider))\n",
    "grouped_event = sessions.groupby(['session_no','event'])['ip'].count().reset_index()\n",
    "grouped_event.head()\n",
    "\n",
    "#pivot and append to the entire data\n",
    "grouped_event_=grouped_event.pivot(index='session_no', columns='event', values='ip')\n",
    "grouped_event_=grouped_event_[['portal_search','portal_view', 'portal_accessed', 'portal_export']]\n",
    "grouped_event_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#append the views and accessed back to the data\n",
    "sessions=pd.merge(sessions, grouped_event_, left_on='session_no', right_on='session_no', how='left')\n",
    "sessions.info()\n",
    "sessions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_=pd.DataFrame(sessions.result_id.str.split(',', expand=True).values).add_prefix('Result_id_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_top_5=sessions_.iloc[ :, 0:5]\n",
    "results_top_5.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping the top 5 for the timebeing\n",
    "results_top_5_= results_top_5.apply(lambda x: x.str.strip(\"[]\"))\n",
    "results_top_5_= results_top_5_.apply(lambda x: x.str.replace(r\"'\", '' ))\n",
    "results_top_5_= results_top_5_.apply(lambda x: x.str.strip())\n",
    "results_top_5_.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "results_top_5_=results_top_5_.replace(r'', np.NaN)\n",
    "results_top_5_.fillna(value=pd.np.nan, inplace=True)\n",
    "#results_top_5_=results_top_5_.replace(r'None', np.NaN)\n",
    "results_top_5_.head(30)\n",
    "#results_top_5_=results_top_5_.dropna(subset=['Result_id_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#append back to the entire data\n",
    "sessions.reset_index(drop=True, inplace=True)\n",
    "results_top_5_.reset_index(drop=True, inplace=True)\n",
    "non_abandon_sessions=pd.concat([sessions, results_top_5_], axis=1, sort=False)\n",
    "non_abandon_sessions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are sessions that have no query but results- removing them for the moment- we can revisit if required\n",
    "non_abandon_sessions_= non_abandon_sessions[non_abandon_sessions['q'].notnull()]\n",
    "\n",
    "non_abandon_sessions_.info()\n",
    "non_abandon_sessions_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subjects with anz codes\n",
    "titles_anz=pd.read_csv('subject_data.csv')\n",
    "titles_anz.head()\n",
    "# titles['id']=titles['id'].astype(str)\n",
    "titles_anz.info()\n",
    "titles_anz.head()\n",
    "# # subjects with tsubject\n",
    "# titles_t=pd.read_csv('titles_tsub_id.csv')\n",
    "# titles_t.head()\n",
    "# titles.info()\n",
    "titles_anz.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "titles_anz=titles_anz.astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the titles to the relvant Id for all the top 5 resutls shown\n",
    "data_1=pd.merge(non_abandon_sessions_, titles_anz[['title','id','final_sub0','final_sub1','final_sub2',\n",
    "                                               'final_sub3', 'final_sub4','final_sub5']],\n",
    "                                                left_on='Result_id_0', right_on='id', how='left'); data_1=data_1.drop(columns=['id']); data_1=data_1.rename(columns={\"title\": \"title_id_0\"})\n",
    "data_2=pd.merge(data_1, titles_anz[['id', 'title']], left_on='Result_id_1', right_on='id', how='left'); data_2=data_2.drop(columns=['id']); data_2=data_2.rename(columns={\"title\": \"title_id_1\"})\n",
    "data_3=pd.merge(data_2, titles_anz[['id', 'title']], left_on='Result_id_2', right_on='id', how='left'); data_3=data_3.drop(columns=['id']); data_3=data_3.rename(columns={\"title\": \"title_id_2\"})\n",
    "data_4=pd.merge(data_3,titles_anz[['id', 'title']], left_on='Result_id_3', right_on='id', how='left'); data_4=data_4.drop(columns=['id']); data_4=data_4.rename(columns={\"title\": \"title_id_3\"})\n",
    "data_final=pd.merge(data_4, titles_anz[['id', 'title']], left_on='Result_id_4', right_on='id', how='left'); data_final=data_final.drop(columns=['id']); data_final=data_final.rename(columns={\"title\": \"title_id_4\"})\n",
    "data_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_final.head(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=data_final[data_final['Result_id_0'].isnull()]\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_final.to_csv(\"final_matched_data_v2.csv\")\n",
    "data_final.to_csv(\"final_matched_data_session30.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
